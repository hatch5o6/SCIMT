{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hatch5o6/.conda/envs/sound/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"google/smol\", \"smoldoc__en_ee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'sl', 'tl', 'srcs', 'trgs', 'factuality', 'is_src_orig'],\n",
      "        num_rows: 130\n",
      "    })\n",
      "})\n",
      "[\"Dude, you won't believe this.\", \"There's this engineer at my school who subsists off coffee.\", 'Like, he drinks it all day long.', \"I'm not even sure he eats real food.\", \"He's like a walking coffee machine.\", 'The other day, I saw him walking down the hall, and he was literally shaking.', 'I asked him if he was okay, and he said he was just \"coming down from a caffeine high.\"', 'I was like, \"Dude, you need to slow down. You\\'re gonna hurt yourself.\"', 'But he just laughed and said, \"I\\'m fine. I\\'m an engineer. I can handle it.\"', \"I don't know how he does it, but he's definitely one of a kind.\", \"I mean, he's the only person I know who can drink coffee and still fall asleep in class.\", \"It's like his body is just used to it.\", \"I'm not sure how long he can keep this up, but I'm kind of impressed by his dedication.\", \"I mean, if he can drink that much coffee and still function, then he's definitely got some serious willpower.\"]\n",
      "['Aƒetɔ, me le edzi xɔ ge ase o.', 'Mɔɖanudɔwɔla aɖe le nye suku si noa coffee ɖeɖe ko ɖe nuɖuɖu teƒe.', 'Abe, enona aha le ŋkekea katã me.', 'Nye me kaɖe edzi be eɖuna nuɖuɖu ŋutɔ o.', 'Ele abe coffe mɔ si le zɔzɔm.', 'Etsɔ si va yi la, me kpɔe wo yina akpata me, eye wole ƒoƒom kpakpaakpa.', 'Me bia be ele nyuiea, eye wogblɔ be, ɖeko ye tso \"coffee ƒe nudzedodoname dzi gbɔ koe ya.\"', 'Me gblɔe nɛ be, \"Aƒetɔ, ehia be na lebena ɖokuiwo, ele nuvevi wɔ ge ɖokuiwo.\"', 'Gake ɖeko woko nu gblɔ be, \"me le sesie, mɔɖaŋudɔwɔla menye. Mateŋu awɔ dɔ le eŋu.\"', 'Nye me nya alekee wowɔ nɛ o, gake ame tɔxɛ aɖe ko wonye.', 'Me be, eya koe nye ame si menya si ateŋu ano coffee gake gateŋu dɔna alɔ le suku xɔme.', 'Ewɔa abe nusia ɖeko woma eƒe lame.', 'Nye me kaɖe edzi vaseɖe ɣekaɣie woanɔ esia dzi o, gake mekpɔ nudzedze le eƒe agbagbadzedze ŋu.', 'Mebe, ne woateŋu ano coffee ma gbegbe aga teŋu anɔteŋu awɔ dɔ la, ke ɖokuidziɖuɖu blibo ŋutɔ le esi.']\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "for item in data['train']:\n",
    "    print(item['srcs'])\n",
    "    print(item['trgs'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"google/smol\", \"smolsent__en_ee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sl', 'tl', 'id', 'src', 'trg', 'is_src_orig'],\n",
      "        num_rows: 863\n",
      "    })\n",
      "})\n",
      "It allows me to work by following my vibes and molding my teaching style to the learning style of the audience.\n",
      "Eɖea mɔ nam be mawɔ dɔ to nye seselelãmewo ŋudɔ wɔwɔ me be matu nye nufiafia ƒe nɔnɔme wòasɔ kple ale si nyaselawo srɔ̃a nui.\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "for item in data['train']:\n",
    "    print(item['src'])\n",
    "    print(item['trg'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 17/17 [00:00<00:00, 428.04 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"aiana94/polynews-parallel\", \"amh_Ethi-deu_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'provenance'],\n",
      "        num_rows: 17\n",
      "    })\n",
      "})\n",
      "{'src': 'ሕንድ፤ ባሎች ሚስቶቻቸውን ለማጀት ሥራቸው ሊከፍሏቸው ነው? ', 'tgt': 'Indien: Werden Ehemänner ihre Frauen für die Hausarbeit entlohnen müssen? ', 'provenance': 'globalvoices'}\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "for item in data['train']:\n",
    "    print(item)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sound",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
