# Outputs
save: /home/hatch5o6/nobackup/archive/CognateMT/PredictCognates/NMT_TEST
test_checkpoint: /home/hatch5o6/nobackup/archive/CognateMT/PredictCognates/NMT.es-an.en_TRIAL_s=1000/checkpoints/epoch=91-step=21620-val_loss=1.9065.ckpt
remove_special_toks: True
verbose: True

# Finetune?
from_pretrained: None

# data
train_data: data/NMT.es-an.en/train.csv
val_data: data/an-en_dev_test/val.csv
test_data: data/an-en_dev_test/test.csv
append_src_token: False
append_tgt_token: False
upsample: False

# tokenizers
src_spm: /home/hatch5o6/nobackup/archive/CognateMT/spm_models/es.an/es.an
tgt_spm: /home/hatch5o6/nobackup/archive/CognateMT/spm_models/en/en

# training
seed: 1000

train_batch_size: 128
val_batch_size: 128
test_batch_size: 128

early_stop: 10
save_top_k: 2
max_epochs: 1000
val_interval: 1.0 # 1 time / epoch

learning_rate: 0.00002

device: cuda

# config
encoder_layers: 6
encoder_attention_heads: 8
encoder_ffn_dim: 2048
encoder_layerdrop: 0.0

decoder_layers: 6
decoder_attention_heads: 8
decoder_ffn_dim: 2048
decoder_layerdrop: 0.0

max_position_embeddings: 512
max_length: 512
d_model: 512
dropout: 0.1
activation_function: gelu