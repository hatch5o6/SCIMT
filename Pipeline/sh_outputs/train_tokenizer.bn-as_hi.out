Starting-----------------------
Mon Jun 16 03:21:22 PM MDT 2025
-------------------------------
Arguments:-
    SPM_TRAIN_SIZE=50000

    SRC_LANGS=bn,as
    SRC_TOK_NAME=bn-as
    TGT_LANGS=hi
    TGT_TOK_NAME=hi

    TRAIN_PARALLEL=/home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-hi/train.csv,/home/hatch5o6/Cognate/code/NMT/data/PLAIN/as-hi/train.csv,/home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-as/train.csv
    VAL_PARALLEL=/home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-hi_dev_test/val.csv,/home/hatch5o6/Cognate/code/NMT/data/PLAIN/as-hi_dev_test/val.csv,/home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-as_dev_test/val.csv
    TEST_PARALLEL=/home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-hi_dev_test/test.csv,/home/hatch5o6/Cognate/code/NMT/data/PLAIN/as-hi_dev_test/test.csv,/home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-as_dev_test/test.csv
    TOK_TRAIN_DATA_DIR=/home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi

    SPLIT_ON_WS=true
    INCLUDE_LANG_TOKS=false
    INCLUDE_PAD_TOK=true
    SPECIAL_TOKS=null
-------------------------------
creating /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi
############################
# make_SC_training_data.py #
############################
Arguments:-
	-train_csvs: /home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-hi/train.csv,/home/hatch5o6/Cognate/code/NMT/data/PLAIN/as-hi/train.csv,/home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-as/train.csv
	-val_csvs: /home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-hi_dev_test/val.csv,/home/hatch5o6/Cognate/code/NMT/data/PLAIN/as-hi_dev_test/val.csv,/home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-as_dev_test/val.csv
	-test_csvs: /home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-hi_dev_test/test.csv,/home/hatch5o6/Cognate/code/NMT/data/PLAIN/as-hi_dev_test/test.csv,/home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-as_dev_test/test.csv
	-out_dir: /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi
------------------------------

### READING ###
Reading /home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-hi/train.csv
Reading /home/hatch5o6/Cognate/code/NMT/data/PLAIN/as-hi/train.csv
Reading /home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-as/train.csv
Reading /home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-hi_dev_test/val.csv
Reading /home/hatch5o6/Cognate/code/NMT/data/PLAIN/as-hi_dev_test/val.csv
Reading /home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-as_dev_test/val.csv
Reading /home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-hi_dev_test/test.csv
Reading /home/hatch5o6/Cognate/code/NMT/data/PLAIN/as-hi_dev_test/test.csv
Reading /home/hatch5o6/Cognate/code/NMT/data/PLAIN/bn-as_dev_test/test.csv
### WRITING ###
deleting /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi
creating /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi
--
Writing bn:
	-/home/hatch5o6/nobackup/archive/data/NLLB/bn_hi/cleaned/src.txt
	total lines for bn now 3481537
	-/home/hatch5o6/nobackup/archive/data/NLLB/bn_as/cleaned/tgt.txt
	total lines for bn now 4494552
	-/home/hatch5o6/nobackup/archive/data/flores200_dataset/dev/ben_Beng.dev
	total lines for bn now 4495549
	-/home/hatch5o6/nobackup/archive/data/flores200_dataset/devtest/ben_Beng.devtest
	total lines for bn now 4496561
TOTAL LINES (BEFORE UNIQUE): 4496561
TOTAL LINES (AFTER UNIQUE): 3708070
Writing bn data (3708070 lines) to /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/bn.txt
--
Writing hi:
	-/home/hatch5o6/nobackup/archive/data/NLLB/bn_hi/cleaned/tgt.txt
	total lines for hi now 3481537
	-/home/hatch5o6/nobackup/archive/data/NLLB/as_hi/cleaned/tgt.txt
	total lines for hi now 3960499
	-/home/hatch5o6/nobackup/archive/data/flores200_dataset/dev/hin_Deva.dev
	total lines for hi now 3961496
	-/home/hatch5o6/nobackup/archive/data/flores200_dataset/devtest/hin_Deva.devtest
	total lines for hi now 3962508
TOTAL LINES (BEFORE UNIQUE): 3962508
TOTAL LINES (AFTER UNIQUE): 3692073
Writing hi data (3692073 lines) to /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/hi.txt
--
Writing as:
	-/home/hatch5o6/nobackup/archive/data/NLLB/as_hi/cleaned/src.txt
	total lines for as now 478962
	-/home/hatch5o6/nobackup/archive/data/NLLB/bn_as/cleaned/src.txt
	total lines for as now 1491977
	-/home/hatch5o6/nobackup/archive/data/flores200_dataset/dev/asm_Beng.dev
	total lines for as now 1492974
	-/home/hatch5o6/nobackup/archive/data/flores200_dataset/devtest/asm_Beng.devtest
	total lines for as now 1493986
TOTAL LINES (BEFORE UNIQUE): 1493986
TOTAL LINES (AFTER UNIQUE): 676967
Writing as data (676967 lines) to /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/as.txt
INCLUDING <pad> TOKEN
SRC_USER_DEFINED_SYMBOLS_STR: <pad>
TGT_USER_DEFINED_SYMBOLS_STR: <pad>

Arguments:-
	--langs = 'bn,as'
	--folder = '/home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi'
	--data = 'None'
	--training_data_size = '50000'
	--save_dir = '/home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/bn-as'
	--spm_model_name = 'bn-as'
	--spm_vocab_size = '8000'
	--spm_model_type = 'bpe'
	--character_coverage = '1.0'
	--seed = '1500'
	--user_defined_symbols = '<pad>'
	--SPLIT_ON_WS = 'true'
langs ['bn', 'as']
DATA LIST ['/home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/bn.txt', '/home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/as.txt']
CREATED DATA_DICT FROM args.langs AND args.folder:
{
  "/home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/bn.txt": 0.5,
  "/home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/as.txt": 0.5
}


creating /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/bn-as
-----------------------------
data_f: /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/bn.txt
ratio: 0.5
size: 3708070
After upsampling: 25000
-----------------------------
data_f: /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/as.txt
ratio: 0.5
size: 676967
After upsampling: 25000


ALL DATA SIZE: 50000
Writing 50000 lines to /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/bn-as/training_data.s=1500.txt
Training tokenizer
model_name: /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/bn-as/bn-as
data_file: /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/bn-as/training_data.s=1500.txt
model_type: bpe
vocab_size: 8000
character_coverage: 1.0
user_defined_symbols: ['<pad>', '▁']
Arguments:-
	--langs = 'hi'
	--folder = '/home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi'
	--data = 'None'
	--training_data_size = '50000'
	--save_dir = '/home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/hi'
	--spm_model_name = 'hi'
	--spm_vocab_size = '8000'
	--spm_model_type = 'bpe'
	--character_coverage = '1.0'
	--seed = '1500'
	--user_defined_symbols = '<pad>'
	--SPLIT_ON_WS = 'true'
langs ['hi']
DATA LIST ['/home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/hi.txt']
CREATED DATA_DICT FROM args.langs AND args.folder:
{
  "/home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/hi.txt": 1.0
}


creating /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/hi
-----------------------------
data_f: /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/hi.txt
ratio: 1.0
size: 3692073
After upsampling: 50000


ALL DATA SIZE: 50000
Writing 50000 lines to /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/hi/training_data.s=1500.txt
Training tokenizer
model_name: /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/hi/hi
data_file: /home/hatch5o6/nobackup/archive/CognateMT/spm_models/bn-as_hi/hi/training_data.s=1500.txt
model_type: bpe
vocab_size: 8000
character_coverage: 1.0
user_defined_symbols: ['<pad>', '▁']
Finished-----------------------
Mon Jun 16 03:22:01 PM MDT 2025
-------------------------------
