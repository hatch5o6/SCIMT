# QuickStart Tokenizer Configuration for es-pt-en
# This tokenizer will be trained on Portuguese->English data with SC-augmented Spanish

# SPM MODELS:
SPM_TRAIN_SIZE=1600

# Source languages: es2pt (SC-transformed Spanish) and pt (Portuguese)
SRC_LANGS=es2pt,pt
SRC_TOK_NAME=SC_es2pt-pt

# Target language: en (English)
TGT_LANGS=en
TGT_TOK_NAME=en

# Distribution: 25% Spanish (es), 25% Portuguese (pt), 50% English (en)
# Note: Using actual file names created by make_tok_training_data.py
DIST=es:25,pt:25,en:50

# Training data paths (using absolute paths from CSVs)
TRAIN_PARALLEL=/Users/ringger/Projects/brendan/SCIMT/charlotte-test/data/csv/nmt_train.csv
VAL_PARALLEL=/Users/ringger/Projects/brendan/SCIMT/charlotte-test/data/csv/nmt_val.csv
TEST_PARALLEL=/Users/ringger/Projects/brendan/SCIMT/charlotte-test/data/csv/nmt_test.csv

# Output directory for tokenizer training data
TOK_TRAIN_DATA_DIR=/Users/ringger/Projects/brendan/SCIMT/charlotte-test/tokenizer_data

# SC Model ID (will match the trained model from test-sc-es-pt.cfg)
SC_MODEL_ID=es_pt_RNN-default_S-1000

# Vocabulary size (smaller for quick test)
VOCAB_SIZE=8000

# Tokenizer options
SPLIT_ON_WS=false
INCLUDE_LANG_TOKS=true
INCLUDE_PAD_TOK=true
SPECIAL_TOKS=null

# Is this for attention transfer? No, just regular CharLOTTE
IS_ATT=false
